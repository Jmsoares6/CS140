        +---------------------------+
        | CS 140                    |
        | PROJECT 3: VIRTUAL MEMORY |
        |  DESIGN DOCUMENT          |
        +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Song Han <songhan@stanford.edu>
Jinchao Ye <jcye@stanford.edu>
Bo Wang <bowang@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

Our design use a space efficient method for frame table, only 4 bytes used
for each frame table entry. The bitmap for user pool is completely removed
since it is redundant together with frame table.
The solution turned out working very well. You are more than welcome to
contact us in case of any confusion.


>> Describe briefly which parts of the assignment were implemented by
>> each member of your team. If some team members contributed significantly
>> more or less than others (e.g. 2x), indicate that here.

Song Han: supplementary page table, swap table 
Jinchao Ye: memory mapped file, design doc 
Bo Wang: frame table, stack growth, clock algorithm 

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

      PAGE TABLE MANAGEMENT
      =====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

<page.h>
/* spte_flags is used to denote the kind of a page: memory mapped file, code, 
   initialized data or uninitialized data */
enum spte_flags
{
  SPTE_M  = 0x1,   /* 1 if memory mapped file */
  SPTE_C  = 0x2,   /* 1 if executable's code segment */
  SPTE_DI = 0x4,   /* 1 if initialized data */
  SPTE_DU = 0x8    /* 1 if uninitialized data */
};

/* Supplemental page table entry, used for each page of memory mapped file
   and code, also data before it has ever been loaded */
struct suppl_pte
{
  uint32_t *pte;                 /* Kernel virtual address to 
                                    the page table entry */
  struct file *file;             /* File this page is mapped to */
  enum spte_flags flags;         /* Types of the page */
  bool writable;                 /* Whether this page is writable */
  off_t offset;                  /* Offset in the file the page is mapped to */
  size_t bytes_read;             /* Number of bytes read from the file */
  struct hash_elem elem_hash;    /* Element for supplemental page table */
};

<thread.h>
/* each thread has a supplementary page table with a lock */
struct thread
{
  ...
  struct hash suppl_pt;              /* Supplemental page table */
  ...
}

<pte.h>
#define PTE_P 0x1               /* 1=present, 0=not present. */
#define PTE_W 0x2               /* 1=read/write, 0=read-only. */
#define PTE_U 0x4               /* 1=user/kernel, 0=kernel only. */
#define PTE_M 0x8               /* 1=memory mapped file, 0=normal memory */
#define PTE_S 0x10              /* 1=shared memory, 0=not shared */
#define PTE_A 0x20              /* 1=accessed, 0=not acccessed. */
#define PTE_D 0x40              /* 1=dirty, 0=not dirty (PTEs only). */
#define PTE_I 0x80              /* 1=pinned, 0=not pinned */
#define PTE_F 0x100             /* 1=being flushed, 0=not being flushed */
#define MAX_SWAP_PAGE_NO 0xfffff

---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

Case 0: The present bit of the pte is set to one. This is the simplest case 
that won't cause page fault and is handled by hardware translation via MMU.

Case 1: Stack growth. We use heuristic method to detect whether this page
fault is caused by stack growth. If so, we allocated a zero page from the user
pool and install the page. This is implemented in exceptino.c: stack_growth()

Case 2: Load from file system. If the page is not present and PTE_M bit of the
page table entry is set, then the page should be loaded from file sytem. We 
use the pointer to PTE as the key to look up the corresponding supplementary 
page table entry (SPTE). We can locate the frame via the file pointer and 
offset. This is implemented in exception.c: load_page_from_file().

Case 3: Load from swap. If the page is not present and PTE_M bit is 0, and the
top 20 bits of PTE is not empty, then it is in swap. The swap frame number is 
obtained from the top 20 bits of PTE (a frame is 8 sectors). Then we can easily
locate the frame in the swap using this swap frame number and swap in the data.
This is implemented in exception.c: load_page_from_swap().

Case 4: If it is not present and PTE_M is 0 and the top 20 bits of PTE is also
0, this means such page doesn't exist. In this case, just exit(-1).

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

We avoid this issue by accessing user data only through user virtual addresses 
(only through the user program's page table). 

---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?

For the memory pool, the original bitmap is replaced with frame table entry. The
frame table entry is mapped one-to-one to the frame in user pool. Each entry
is 4 bytes. If the entry is zero, it means that the frame is empty. Otherwise, 
each frame table entry stores a pointer to either
1)  page table entry if the page is present or in swap
 or  
2)  supplementary page table entry if the page is in file

Any process that need a new frame need to first acquire the memory pool's lock 
before scanning the frame table for an empty frame (previously scan the bitmap).
This eliminates race condition. The steps are: 	

When we allocate a page, we will call palloc_get_page(), which then calls 
palloc_get_multiple(). If there are free frames, then it'll be returned. 
Otherwise, page_out_then_get_page() will be called. Both functions have to 
acquire pool->lock before they can scan the frames or do clock algorithm to 
get a frame. Therefore one process have to wait till the other process get a 
frame before it can search for a new frame.

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?

All pages that are currently in memory can be located by page table entries as 
in project 2.

All pages that are in swap can also be located by page table entries. The 
address of each allocated swap frame is stored as the top 20 bits in 
corresponding page table entry (where physical address was stored when this page
was in memory). Therefore, we don't even need to lookup in supplementary page 
table. We only need the top 20 bits in the PTE to locate the frame in swap.
Comparing with creating a supplementary page table entry for a swap page, this 
method saves both time and space.

All pages that are in file (memory mapped file, code or data) can be located 
by supplementary page table entries. We choose to use hash table to implement
our supplementary page table because insertion, deletion and lookup only need
O(1) time in hash table. Therefore, we can do virtual-to-physical mappings very 
efficiently.  

           PAGING TO AND FROM DISK
           =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

<frame.h>
/* global frame table as a member of pool */   
struct frame_table
{
  size_t page_cnt;    /* total pages in user/kernel pool */
  uint32_t **frames;  /* frames stores pointers to PTE or SPTE */
  size_t clock_cur;   /* used for clock algorithm */
};

Here the **frames pointer is stored below the userpool, occupying 4 Byte
for each frame. It replaces the previous pool bit map since bitmap is 
redundant with the existence of frame table.

<palloc.c>
/* Replaced the pool's bitmap with frame table*/
struct pool
{
  struct lock lock;                   /* Mutual exclusion. */
  struct frame_table frame_table;     /* Raplaced bitmap with framb_table/
  uint8_t *base;                      /* Base of pool. */
};

<swap.h>
/* global swap table to track the usage of each sector in swap */
struct swap_table
  {
    struct block *swap_block;  /* Swap block used for swap table on the disk */
    struct bitmap *bitmap;     /* Bitmap keeps track of allocation status */
    struct lock lock;          /* Lock to synchronize access to swap table */
  };

struct thread
{
  ...
  void *esp;                          /* Saved stack pointer for interrupt
                                         in the kernel */
  bool in_syscall;                    /* True if thread is in system call */
  ... 
}

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

We use clock algorithm to choose a frame to evict. As shown in B1, we have a 
clock "hand" clock_cur defined in the struct frame_table. Whenever we need to 
choose a frame to evict, the "hand" clock_cur scans through the frames in the 
frame_table. Since we don't implement sharing, there is only 1 corresponding PTE
in user memory for each frame. In our design, frames store the pointers to PTEs
or SPTEs, and each SPTE also has a PTE pointer in it. Therefore, we can access
each frame's corresponding PTE. 

We first check PTE_I bit of the corresponding PTE. If it is 1, then it means
that the corresponding frame is being swapped out or written to file. Therefore
we increment the "hand" clock_cur and continue to search.

Else if the PTE_A bit of the corresponding PTE is 1, it means that this frame 
has recently been visited recently. In this case, we reset the PTE_A bit, flush 
TLB, increment the "hand" clock_cur and continue to search.

Else then the PTE_A bit of the corresponding PTE is 0, it means that this frame
hasn't been visited in the last cycle. We then will choose this frame to evict!

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

In our design, a frame table entry stores pointer to
1)  corresponding page table entry if the page is present or in swap
or  
2)  corresponding supplementary page table entry if the frame is in file
These two cases are discriminated by manually decrease the stored user address
of spte by PYS_BASE, and re-add it back when we use it. 

When a process P obtains a frame that was previously used by a process Q, it 
will first clear the PTE_P bit in the Q's PTE corresponding to the frame, write
it to swap or file. If it is write to swap, the swap_frame_no is stored in the 
top 20 bits in the PTE. If it is write to file, then find the position according
to the file pointer and offset in the corresponding SPTE. 

The frame table entry originally pointed to Q's PTE (if the old page was not 
memory mapped file) or SPTE (if the old page was memory mapped file). We then 
make the frame table entry point to P's corresponding PTE (if the new page is 
not memory mapped file) or SPTE (if the new page is memory mapped file). By 
changing the content of the frame table entry, we reflect Q no longer has the 
frame and P has it.

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

struct thread
{
  ...
  void *esp;                          /* Saved stack pointer for interrupt
                                         in the kernel */
  ... 
}

First of all, we need to obtain the current value of the user program's stack 
pointer. Whenever we enter a system call, we save user program's stack pointer 
as esp in the struct thread. Whenever a page fault occurs, we can check whether
it is caused by kernel or a user process by checking the f->error_code.

If the page fault is caused by kernel, then we retrieve user program's stack 
pointer through thread_current()->esp. If the page fault is caused by user 
program, then the f->esp, i.e. esp in the interrupt frame, is the user 
program's stack pointer.

Once we get the user program's stack pointer, we check whether all the following
conditions are met:
1) fault_addr == user_esp - 4      /* PUSH  */
   or fault_addr == user_esp - 32  /* PUSHA */
   or fault_addr >= user_esp       /* SUB $n, %esp; MOV ..., m(%esp) */
2) fault_addr >= STACK_BASE        /* Stack limit 8MB, cannot extend below
                                      STACK_BASE */
3) (pte == NULL) ||                /* Stack growth */
   (*pte & PTE_ADDR) == 0))        /* Lazily load, only PTE has been 
                                      generated, no frame allocated yet */

If all of the above three conditions are met, then our heuristic says this 
should cause the stack to be extended into the page that faulted.

---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

The following data structures has lock: 
1. Pool lock: entire pool uses the same lock, only one process can acquire 
   this lock. Each thread must first acquire this lock and then sweep the 
   frames with clock algorithm. This lock is released before doing I/O.
2. Pin-lock: Each process must first hold the pool lock and then acquire the
   pin-lock. This hierarchy structure prevented deadlock. Process should acquire
   this lock before setting or unsetting the page table entry.
3. Global File System Lock: only held during file operation. Won't try to
   acquire other locks when doing file reading/writing since we have already
   pre-loaded an pinned the buffer pages so it won't cause page faults during
   file reading/writing.
4. Flush lock: inside the condition variable to let Q wait for P fully evicts 
   its page to swap or filesys. This lock is at the bottom of the lock hierarchy. 
   Process won't try to acquire other locks when holding this lock. It won't
   cause deadlock.

Four conditions for deadlock:
Limited access. 
No preemption. 
Multiple independent requests. 
Circularity in the graph of requests and ownership.

Here we prevented the fourth condition by hierarchical lock acquire.


>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

Monitor is used to avoid race, letting Q wait until P fully evicts Q's
frame to swap or file. The shared variable is the PTE_F bit. The mechanism
is as follows:

In the clock algorithm, if P find Q's page X as a victim to be evicted,
it acquires the flush lock, set the PTE_F bit on the pte of X, and then
release the lock. With the PTE_F bit set, it can safely carry on a series 
of tasks: including set the non-present bit, writing the frame to swap or
file. Upon finishing the eviction, P will acquire the flush lock again, 
unset the PTE_F bit, and broadcast all the waiters for the condition 
variable. Finally P releases the lock. This is coded in palloc.c, function
page_out_then_get_page(). Since P doesn't hold the lock while doing I/O, it
does not hurt concurrency. 

If process Q is faulting on the same page of X, it first palloc a frame. 
Then while the PTE_F bit is set, Q has to wait for the flush condition variable
before swapping in or read in its content. When P has already finished the 
eviction of Q's frame, Q will get signaled and finish waiting. Then Q could 
continue to handle its page fault, either swapping in or reading from file. 

Here we used broadcast to give every waiting process a chance to wake up on
any process's eviction finishes, although it seems not paired. However, the
while loop that checks the PTE_F bit outside the cond_wait() will finally 
guarantee the pairing of evicting and faulting back in the same page.


>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

While in process P a page is being read from the file system or swap, the PTE_I 
bit (pin bit) of the PTE corresponding to this page is set to 1. Whenever a 
second process Q wants to access the corresponding frame, e.g., evicting it, 
it will check the PTE_I bit of the PTE the frame table entry points to. If it 
is set to 1, Q will not be able to modify it. In clock algorithm, Q will skip
this frame since there's page being read from file or swap to this frame. Q will
continue to search following frames table entries to find a frame to evict.

Once the page if fully loaded into the frame, the PTE_I bit of the P's PTE will
then be set to 0 and now a second process can evict this frame. 

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

For file system system calls such as read() and write(), we pin the pages of
the buffer that we are going to read or write, and the file name
char buffer. This is because we have to acquire the global file system 
lock when doing the file reading or writing, and we can not try to 
acquire the same lock for a second time when handling page fault (for 
example, read from mmap files). So we make sure that page fault wouldn't
happen during file system calls, which is done by preload_user_memory(). We 
first check if all the pages has been allocated, if not, we allocated
them as needed. We also check if the frame is loaded in memory, if not,
those frames are loaded into memory one by one. Then we pin those pages 
before acquiring the global filesys lock. After releasing the filesys lock
we unpin the pages.

To handle invalid virtual address happening in kernel, we added in_syscall
flag in thread struct. This flag is set on entering the syscall handler.
If page fault happened in kernel mode but in_syscall has been set, then 
it means this page fault happened during syscall and we don't kill the 
kernel. Only when the page fault happened in kernel mode but not in syscall
do we kill the kernel.

False address access was detected at the beginning of each syscall handler.
We have checked NULL pointer, above PHY_BASE pointer for the whole buffer.
Inside preload_user_memory(), an unallocated page was below the stack
pointer is also detected as illegal. These false attempts won't kill the 
kernel. 


---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

We are trying to minimize the synchronization's impact on parallelism. We
guaranteed when one process is doing I/O on page fault, other process don't
have to wait for this I/O to finish and they can start to handle their page 
fault concurrently. Although we use global pool lock to make sure only one
process can access the pool at a time, we released this lock before it start
doing I/O, either writing to swap or writing to file system. This result in
better concurrency.

We used monitor for writing page to swap and another monitor for writing page
to file sytem. In this way, we avoid race conditions while a process is evicting
a frame to swap/file while another process is trying to page in this frame (but 
hasn't been fully written to swap/file yet). We avoid this by acquiring the 
corresponding lock and setting the PTE_F bit in PTE while writing it to 
swap/file, clearing the PTE_F bit, broadcasting, and releasing the lock after 
the frame is fully written out. On the other hand, if a page needs to be paged
in from swap/file, it will needs to first acquire corresponding lock, wait on 
the conditional variable and check whether PTE_F bit is cleared, and then 
release the lock if it is cleared.

This design enables pintos to evict a frame to swap while paging in a
second frame from file, or vice versa. This is because we use separate locks and 
conditional variables for swap and file.

We don't add a lock for each frame because 
1) we can only write 1 file to swap/file at a time. Fine-grained locks will not
help parallelism in this case.
2) there are too many locks then. 


       MEMORY MAPPED FILES
       ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

<thread.h>
struct thread
{
  ...
  struct hash mmap_files;            /* Hash table of memory mapped files */
  int mmap_files_num_ever;           /* # of files ever mapped, used as key */
  ...
}
We store information about memory mapped files as a hash table "mmap_files" in 
each thread. "mmap_files_num_ever" is used as a key in this hash table.

<mmap.h>
/* Memory mapped file */
struct mmap_file
{
  int mid;
  struct file *file;                  /* File the memory is mapped to */
  uint8_t *upage;                     /* User virtual address of the first
                                         mapping page */
  size_t num_pages;                   /* Number of pages mapped to the file */
  struct hash_elem elem;
};
We keep id, file pointer, starting user virtual address and number of pages in 
this struct.

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

The hash table "mmap_files" is initialized when a process starts. Once a user
process maps a file to memory, pintos will populate page table and supplementary 
page table according to the information of the file to be mapped. When some 
process queries to the mapped data, it will cause a page fault and actually 
load the corresponding page. When the process unmaps the file, pintos will free
corresponding frames and supplementary page table entries and clear page table
entries. For every mapped page, if the page is dirty, write it back to the file.
When a process terminates, unmap all of its memory mapped files.

In page fault handler, there are 4 cases:
The first case is that the fault page is for stack growth. This is checked by 
comparing the fault address with stack pointer. In this case, we call 
stack_growth() to allocate a new frame. 
The second case is that the fault page should be loaded from swap. The page 
content might be data, stack, etc, but not memory mapped file. We call 
load_page_from_swap() in this case.
The third case is that the fault page should be loaded from memory mapped file. 
Since memory mapped file use itself as backing store, We will call 
load_page_from_file() in this case. We use PET_M bit and present bit in PTE to
see whether the page should be loaded from memory mapped file.
The fourth case is none of the above. We simply call _exit(-1) here.

The eviction algorithm is implemented in page_out_then_get_page() in palloc.c.
If the page should be evicted is a memory mapped file page, then write it back
to the file. If the page should be evicted to swap, then write it to swap.
Another difference is that when a swap page is evicted, we record the 
swap_frame_no in corresponding PTE, while for memory mapped file, the offset 
and file pointer are already stored in corresponding supplementary page table 
entry.


>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

We calculate how many pages the mapping needs by round up file_length/PGSIZE. 
Then for each of the pages (the first page starts at the virtual address 
provided by the user), we call lookup_page(t->pagedir, page addr, false) 
to see whether there is a corresponding PTE for this page address in the page 
directory of current thread. If there is, this means an overlap and MAP_FAILED
is returned. 


---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

In our spte_flag in supplementary page table entries, there are 4 kinds:
enum spte_flags
{
  SPTE_M  = 0x1,   /* 1 if memory mapped file */
  SPTE_C  = 0x2,   /* 1 if executable's code segment */
  SPTE_DI = 0x4,   /* 1 if initialized data */
  SPTE_DU = 0x8    /* 1 if uninitialized data */
};

When memory mapped file pages trigger page fault, our pintos will call 
load_page_from_file(). 

We treat memory mapped files and code as the same in the page_fault handler and
the eviction process. We have a bit PTE_M in PTE to denote whether the page is 
memory mapped. Because once loaded, the memory mapped file pages and code pages 
both set their PTE_M bit in their PTEs to be 1. We haven't seen any disadvantage
for sharing code for these two kinds of pages.

Their are two kinds of data, initialized data and uninitialized data. When we 
load segment lazily, we add PTEs with PET_M set to 1 to page directory for them.
For the first time of page fault, they are treated as memory mapped files, 
except uninitialized data is set as 0 instead of being loaded from file. After
they are loaded for the first time, we set the PTE_M bit in their PTEs to be 0.
Then they will be swapped between memory and swap afterwards. The data pages do
not share much code with memory mapped files because they mainly interact with 
swap once they are loaded from executables.

         SURVEY QUESTIONS
         ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
